{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries needed\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributes for data: ['DESCR', 'data', 'filenames', 'target', 'target_names']\n",
      "attributes for test: ['DESCR', 'data', 'filenames', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Fetch the training data\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "# newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "# Fetch the test data\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "# newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "print(\"attributes for data:\",dir(newsgroups_train))\n",
    "print(\"attributes for test:\",dir(newsgroups_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training data: 11314\n",
      "# of testing data: 7532\n",
      "category: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "length of category: 20\n"
     ]
    }
   ],
   "source": [
    "len_train = len(newsgroups_train.data)\n",
    "len_test = len(newsgroups_test.data)\n",
    "print(\"# of training data:\",len_train)\n",
    "print(\"# of testing data:\", len_test)  \n",
    "\n",
    "train_list_category = []\n",
    "for target_names in newsgroups_train.target_names and newsgroups_test.target_names:\n",
    "    train_list_category.append(target_names)\n",
    "    \n",
    "        \n",
    "print(\"category:\",train_list_category)    \n",
    "print(\"length of category:\",len(train_list_category))\n",
    "\n",
    "# print(newsgroups_train.data[20000])  # print the first document\n",
    "# print(\"\\nClass label:\", newsgroups_train.target[20000])  # print its associated label\n",
    "# print(\"\\nClass name:\", newsgroups_train.target_names[newsgroups_train.target[0]])  # print the name of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000) # stop words are removed like and and the\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "\n",
    "# Transform the test data\n",
    "X_test = vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "# Target labels\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Training accuracy: 0.8611\n",
      "Logistic Regression - Test accuracy: 0.6471\n"
     ]
    }
   ],
   "source": [
    "# Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Score on training and test data\n",
    "logreg_train_score = logreg.score(X_train, y_train)\n",
    "logreg_test_score = logreg.score(X_test, y_test)\n",
    "\n",
    "print(f\"Logistic Regression - Training accuracy: {logreg_train_score:.4f}\")\n",
    "print(f\"Logistic Regression - Test accuracy: {logreg_test_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Training accuracy: 0.9712\n",
      "Decision Tree - Test accuracy: 0.4365\n"
     ]
    }
   ],
   "source": [
    "# Create a decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a decision tree classifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Score on training and test data\n",
    "dtree_train_score = dtree.score(X_train, y_train)\n",
    "dtree_test_score = dtree.score(X_test, y_test)\n",
    "\n",
    "print(f\"Decision Tree - Training accuracy: {dtree_train_score:.4f}\")\n",
    "print(f\"Decision Tree - Test accuracy: {dtree_test_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC - Training accuracy: 0.9725\n",
      "LinearSVC - Test accuracy: 0.6918\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machines (LinearSVC)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_test = vectorizer.transform(newsgroups_test.data)\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc_model = LinearSVC(dual=False)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = svc_model.score(X_train, y_train)\n",
    "test_accuracy = svc_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"LinearSVC - Training accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"LinearSVC - Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost - Training accuracy: 0.4167\n",
      "AdaBoost - Test accuracy: 0.3745\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Initialize AdaBoost classifier\n",
    "ada_clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "\n",
    "# Train AdaBoost\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get training and test accuracies\n",
    "train_accuracy = ada_clf.score(X_train, y_train)\n",
    "test_accuracy = ada_clf.score(X_test, y_test)\n",
    "\n",
    "print(\"AdaBoost - Training accuracy:\", round(train_accuracy, 4))\n",
    "print(\"AdaBoost - Test accuracy:\", round(test_accuracy, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Training accuracy: 0.9747\n",
      "Random Forest - Test accuracy: 0.5928\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Train the classifier\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get training and test accuracies\n",
    "train_accuracy_rf = rf_clf.score(X_train, y_train)\n",
    "test_accuracy_rf = rf_clf.score(X_test, y_test)\n",
    "\n",
    "print(f\"Random Forest - Training accuracy: {train_accuracy_rf:.4f}\")\n",
    "print(f\"Random Forest - Test accuracy: {test_accuracy_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Training accuracy: 0.3641\n",
      "Gradient Boosting - Test accuracy: 0.3031\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the Gradient Boosting classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "\n",
    "# Train the Gradient Boosting classifier\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate training accuracy\n",
    "train_accuracy = gb_clf.score(X_train, y_train)\n",
    "print(f\"Gradient Boosting - Training accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = gb_clf.score(X_test, y_test)\n",
    "print(f\"Gradient Boosting - Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
