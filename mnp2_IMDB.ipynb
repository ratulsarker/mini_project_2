{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries needed\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data into usable matrices\n",
    "neg_folder = 'aclImdb/test/neg'\n",
    "pos_folder = 'aclImdb/test/pos'\n",
    "\n",
    "# Initialize empty lists to store the text and labels\n",
    "reviews = []\n",
    "labels = []\n",
    "\n",
    "# Read and preprocess positive reviews\n",
    "for filename in os.listdir(pos_folder):\n",
    "    with open(os.path.join(pos_folder, filename), 'r', encoding='utf-8') as file:\n",
    "        review = file.read()\n",
    "        # Preprocess the review as needed\n",
    "        # For example, you can remove punctuation and convert to lowercase\n",
    "        review = review.lower()\n",
    "        # Append the preprocessed review and label to the lists\n",
    "        reviews.append(review)\n",
    "        labels.append(1)  # 1 for positive review\n",
    "\n",
    "\n",
    "# Read and preprocess negative reviews\n",
    "for filename in os.listdir(neg_folder):\n",
    "    with open(os.path.join(neg_folder, filename), 'r', encoding='utf-8') as file:\n",
    "        review = file.read()\n",
    "        # Preprocess the review as needed\n",
    "        # For example, you can remove punctuation and convert to lowercase\n",
    "        review = review.lower()\n",
    "        # Append the preprocessed review and label to the lists\n",
    "        reviews.append(review)\n",
    "        labels.append(0)  # 0 for negative review\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust max_features as needed\n",
    "X = vectorizer.fit_transform(reviews)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-Fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Training accuracy: 0.8827\n",
      "Logistic Regression - Test accuracy: 0.8622\n"
     ]
    }
   ],
   "source": [
    "# Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Score on training and test data\n",
    "logreg_train_score = logreg.score(X_train, y_train)\n",
    "logreg_test_score = logreg.score(X_test, y_test)\n",
    "\n",
    "print(f\"Logistic Regression - Training accuracy: {logreg_train_score:.4f}\")\n",
    "print(f\"Logistic Regression - Test accuracy: {logreg_test_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Training accuracy: 1.0000\n",
      "Decision Tree - Test accuracy: 0.6974\n"
     ]
    }
   ],
   "source": [
    "# Create a decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a decision tree classifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Score on training and test data\n",
    "dtree_train_score = dtree.score(X_train, y_train)\n",
    "dtree_test_score = dtree.score(X_test, y_test)\n",
    "\n",
    "print(f\"Decision Tree - Training accuracy: {dtree_train_score:.4f}\")\n",
    "print(f\"Decision Tree - Test accuracy: {dtree_test_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machines (LinearSVC)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(imdb_train.data)\n",
    "X_test = vectorizer.transform(imdb_test.data)\n",
    "y_train = imdb_train.target\n",
    "y_test = imdb_test.target\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc_model = LinearSVC(dual=False)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = svc_model.score(X_train, y_train)\n",
    "test_accuracy = svc_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"LinearSVC - Training accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"LinearSVC - Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Initialize AdaBoost classifier\n",
    "ada_clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "\n",
    "# Train AdaBoost\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get training and test accuracies\n",
    "train_accuracy = ada_clf.score(X_train, y_train)\n",
    "test_accuracy = ada_clf.score(X_test, y_test)\n",
    "\n",
    "print(\"AdaBoost - Training accuracy:\", round(train_accuracy, 4))\n",
    "print(\"AdaBoost - Test accuracy:\", round(test_accuracy, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Train the classifier\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get training and test accuracies\n",
    "train_accuracy_rf = rf_clf.score(X_train, y_train)\n",
    "test_accuracy_rf = rf_clf.score(X_test, y_test)\n",
    "\n",
    "print(f\"Random Forest - Training accuracy: {train_accuracy_rf:.4f}\")\n",
    "print(f\"Random Forest - Test accuracy: {test_accuracy_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the Gradient Boosting classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "\n",
    "# Train the Gradient Boosting classifier\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate training accuracy\n",
    "train_accuracy = gb_clf.score(X_train, y_train)\n",
    "print(f\"Gradient Boosting - Training accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = gb_clf.score(X_test, y_test)\n",
    "print(f\"Gradient Boosting - Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
